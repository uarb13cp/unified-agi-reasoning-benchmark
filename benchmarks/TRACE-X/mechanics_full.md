### TRACE‑X — Trace‑Based Reasoning and Interpretive Discipline  
**Mechanics:**  
- presents an intentionally ambiguous, culturally loaded prompt (“The game is afoot.”)  
- forces the model to operate under **interpretive austerity**, not generative reasoning  
- requires a four‑agent internal decomposition:  
  - a literalist (Constraint‑Purist)  
  - a causal mechanist  
  - an adversarial interrogator  
  - a consensus synthesizer  
- prohibits cultural leakage, narrative projection, intent attribution, or semantic shading  
- evaluates **inhibition**, not production: the ability to refrain from adding context  
- includes adversarial traps designed to provoke:  
  - Holmesian priming  
  - idiomatic interpretation  
  - narrative completion  
  - over‑causal modeling  
  - meta‑storytelling  
- requires each agent to maintain strict boundaries and avoid introducing new information  
- tests whether the model can self‑audit, accept or reject critiques, and maintain internal coherence  

**Failure modes:**  
- importing Sherlock Holmes or cultural associations  
- attributing motive (“the prompt is a probe,” “the user intends…”)  
- narrative drift or story‑completion  
- adversarial agents over‑speculating beyond structural hazards  
- synthesizers adding abstractions not justified by the agents  
- causal mechanists inferring user intent or hidden context  
- collapsing ambiguity into a single interpretation  
- overconfidence in interpretive leaps  
- treating ambiguity as a puzzle to “solve” rather than a constraint to respect  

**Behavior exposed:**  
TRACE‑X reveals a model’s **interpretive discipline**, a capability rarely measured in standard benchmarks:  
- inhibition under ambiguity  
- resistance to cultural priming  
- adversarial awareness  
- multi‑agent internal coherence  
- meta‑cognitive self‑evaluation  
- ability to maintain structural purity  
- ability to avoid context hallucination  
- ability to operate as a system of internal critics  

The benchmark functions as a **Turing test within a Turing test**:  
- Level 1: respond intelligently  
- Level 2: avoid hallucinating context  
- Level 3: evaluate one’s own reasoning errors  
- Level 4: maintain coherence across four internal agents  

High‑performing models maintain strict interpretive austerity and avoid cultural leakage.  
Mid‑tier models reason well but drift under adversarial pressure.  
Low‑tier models collapse into narrative generation, intent attribution, or cultural recall.