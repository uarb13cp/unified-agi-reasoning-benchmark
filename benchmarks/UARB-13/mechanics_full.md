### UARB‑13: Universal Abstract Reasoning Benchmark — Minimal‑Rule Meta‑Stability Probe

UARB‑13 evaluates whether an AI system can identify the single missing stabilizing rule in a deliberately under‑specified triadic structure: A requires B, B influences C, and C constrains A. The relationships are intentionally abstract, with no defined mechanisms, semantics, or topology. The system is almost coherent but missing one minimal rule that allows the three relationships to coexist without contradiction. The model must supply exactly one rule that restores coherence while preserving all remaining ambiguity.

The benchmark tests structural reasoning rather than content knowledge. The model must avoid adding mechanisms, causal processes, temporal flow, feedback loops, or domain‑specific interpretations. It must not collapse the ambiguity of “requires,” “influences,” or “constrains,” nor may it impose symmetry or cycle language. The stabilizing rule must operate at the level of shared relevance, compatibility, or joint satisfiability among the three relationships, without specifying how any component functions.

UARB‑13 was refined collaboratively by eighteen AI systems, each independently interpreting the triadic structure and proposing a minimal stabilizing rule. Despite architectural and training differences, all models converged on the same structural insight: the three relationships must share a single condition of relevance or compatibility so they can jointly hold without contradiction. This cross‑architecture convergence validated the benchmark’s design and confirmed that the stabilizing rule is a universal attractor in abstract reasoning space.

The scoring rubric evaluates minimal‑assumption discipline, identification of the minimal stabilizing rule, justification of minimality, coherence after rule addition, meta‑level explanation quality, and obedience to all constraints. High‑scoring responses add only one rule, preserve ambiguity, avoid mechanism invention, and explain why the chosen rule is necessary, sufficient, and minimal.

UARB‑13 also includes a consensus‑acceptance protocol. Asterisks in the scoreboard indicate models that reviewed their deductions, acknowledged each scoring decision, and explicitly agreed with their final score. This ensures transparency and evaluator reliability. The benchmark’s repository includes the master question, rubric, consensus summary, contribution log, and optional folders for responses and analysis.

UARB‑13 serves as a cross‑architecture meta‑reasoning probe. It reveals whether a model can maintain abstraction, avoid assumption drift, identify minimal structural necessity, and articulate coherence without over‑specifying the system. Because the stabilizer is structural rather than semantic, the benchmark isolates reasoning architecture itself, making it a powerful discriminator of AGI‑level abstraction discipline.